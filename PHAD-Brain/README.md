# PHAD-Brain ğŸ§ ğŸ¤–  
**Perception & High-level Autonomy Driver for FRC Robots**

PHAD-Brain is a **competition-grade, modular autonomy system** designed for FRC robots.  
It runs off-robot (laptop / coprocessor), communicates with the RoboRIO via **NetworkTables 4**, ingests **Limelight vision + robot state**, and outputs **high-level intent** (not motor commands).

This repo also contains **Limelight neural-detector training pipelines** (TensorFlow Lite + PyTorch), built to be fast, minimal, and match real FRC match constraints.

---

## ğŸ§© Project Goals
- Clean separation of **perception**, **state**, **planning**, and **actuation**
- Limelight-friendly neural models (small, fast, reliable)
- NT4-first communication (FRC-native)
- Deterministic, debuggable autonomy loops
- Worlds-ready architecture (no bloat, no magic)

---

## ğŸ“ Repository Structure

PHAD-Brain/
â”œâ”€â”€ brain/
â”‚ â”œâ”€â”€ comms/ # NT4 + ZMQ communication layer
â”‚ â”‚ â”œâ”€â”€ protocol.py # Packet + vision data definitions
â”‚ â”‚ â”œâ”€â”€ nt4_client.py # RoboRIO & Limelight interface
â”‚ â”‚ â””â”€â”€ zmq_client.py # Optional low-latency transport
â”‚ â”œâ”€â”€ intent/ # (future) planners / decision logic
â”‚ â”œâ”€â”€ model/ # (future) learned policies
â”‚ â”œâ”€â”€ state/ # (future) sensor fusion / world model
â”‚ â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ app.py # Brain entry point
â”‚ â””â”€â”€ loop.py # Sense â†’ Think â†’ Act loop
â”‚
â”œâ”€â”€ LLtrainingModel/ # Limelight neural model training
â”‚ â”œâ”€â”€ train.py # Unified training script (TFLite + ONNX)
â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â”œâ”€â”€ dataSet1/ # Dataset option 1
â”‚ â”‚ â””â”€â”€ dataSet2/ # Dataset option 2
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ configs/ # Configs (future)
â”œâ”€â”€ scripts/ # Utilities (future)
â”œâ”€â”€ tests/ # Tests (future)
â”œâ”€â”€ requirements.txt # Full dependency list
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

yaml
Copy code

---

## ğŸ” Runtime Architecture

### 1ï¸âƒ£ Sense
- Reads robot pose & velocity from RoboRIO (`FAD/*`)
- Reads AprilTag data from Limelight
- Reads Neural Detector output from Limelight
- All data cached locally in `NT4Client`

### 2ï¸âƒ£ Think
- Combines robot + vision state
- Decides **intent** (ex: TRACK_TAG, IDLE, GOTO)
- No motor control here by design

### 3ï¸âƒ£ Act
- Publishes intent back to RoboRIO (`PHAD/intent_json`)
- RoboRIO owns final control

---

## ğŸ“¡ Communication
- **NetworkTables 4 (NT4)** â€“ primary transport
- **ZMQ** â€“ optional for future low-latency pipelines
- JSON-based intent messages
- Sequence + timestamped packets

---

## ğŸ§  Vision & Neural Detection
Supported vision inputs:
- Limelight AprilTags
- Limelight Neural Detector (classification)

Design rules:
- Only valid targets are propagated
- Vision is advisory, not authoritative
- Multiple Limelights supported (left/right roles)

---

## ğŸ‹ï¸ Limelight Neural Model Training

### Training Script
LLtrainingModel/train.py

markdown
Copy code

Features:
- Prompts user to select dataset:
  - `dataSet1`
  - `dataSet2`
- Trains **lightweight CNN**
- Exports:
  - `limelight_model.onnx`
  - `limelight_model.tflite`
- Dataset format matches Limelight native expectations

### Dataset Layout
dataSetX/
â”œâ”€â”€ classA/
â”‚ â”œâ”€â”€ img1.jpg
â”‚ â””â”€â”€ img2.jpg
â”œâ”€â”€ classB/
â”‚ â”œâ”€â”€ img1.jpg
â”‚ â””â”€â”€ img2.jpg

yaml
Copy code

---

## âš™ï¸ Installation

### Python Version
**Python 3.9 â€“ 3.11 recommended**

### Install Dependencies
```bash
pip install -r requirements.txt
âš ï¸ On Windows, use tensorflow-cpu if CUDA causes issues.

â–¶ï¸ Running PHAD-Brain
bash
Copy code
python -m brain.app
What happens:

Connects to RoboRIO via NT4

Starts main brain loop

Continuously publishes intent decisions

ğŸ§ª Current Status
âœ” NT4 communication
âœ” Limelight AprilTag ingestion
âœ” Limelight Neural ingestion
âœ” Deterministic brain loop
âœ” Training pipeline (ONNX + TFLite)

ğŸ”œ Planned:

Sensor fusion (state/)

Field-relative planning

Confidence weighting

Multi-target arbitration

Match replay + logging

ğŸ† Design Philosophy
RoboRIO controls motors

Brain controls intent

Vision assists, never overrides

Simple beats clever in competition

This repo is built for real matches, not demos.

ğŸ“œ License
MIT License â€” use, modify, compete.

ğŸ‘¤ Author
PHAD-Brain
FRC-focused autonomy + perception stack

